---
title: Kwantumbibliotheek voor machine learning
description: Meer informatie over hoe machine learning wordt gebruikt op Quantum systemen
author: alexeib2
ms.author: alexeib
ms.date: 11/22/2019
ms.topic: article
uid: microsoft.quantum.libraries.machine-learning.intro
no-loc:
- Q#
- $$v
ms.openlocfilehash: 9f7f892fb2b76432942c86163497c22f0c73d51f
ms.sourcegitcommit: 9b0d1ffc8752334bd6145457a826505cc31fa27a
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 09/21/2020
ms.locfileid: "90833795"
---
# <a name="introduction-to-quantum-machine-learning"></a><span data-ttu-id="19dff-103">Inleiding tot Quantum Machine Learning</span><span class="sxs-lookup"><span data-stu-id="19dff-103">Introduction to Quantum Machine Learning</span></span>

## <a name="framework-and-goals"></a><span data-ttu-id="19dff-104">Framework en doel stellingen</span><span class="sxs-lookup"><span data-stu-id="19dff-104">Framework and goals</span></span>

<span data-ttu-id="19dff-105">Quantum encoding en verwerking van informatie is een krachtig alternatief voor klassieke machine learning Quantum-classificaties.</span><span class="sxs-lookup"><span data-stu-id="19dff-105">Quantum encoding and processing of information is a powerful alternative to classical machine learning Quantum classifiers.</span></span> <span data-ttu-id="19dff-106">Met name de IT-mede werkers kunnen gegevens coderen in Quantum registers die beknopt zijn ten opzichte van het aantal functies, waardoor de Quantum Entanglement als reken kundige resource wordt aangewend en de quantum meting voor klasse-demijnen wordt aangewend.</span><span class="sxs-lookup"><span data-stu-id="19dff-106">In particular, it allows us to encode data in quantum registers that are concise relative to the number of features, systematically employing quantum entanglement as computational resource and employing quantum measurement for class inference.</span></span>
<span data-ttu-id="19dff-107">Circuit Center Quantum-classificatie is een relatief eenvoudige Quantum oplossing die gegevens codering combineert met een snel entangling/Disentangling Quantum circuit, gevolgd door meting om klassen labels van gegevens voorbeelden af te leiden.</span><span class="sxs-lookup"><span data-stu-id="19dff-107">Circuit centric quantum classifier is a relatively simple quantum solution that combines data encoding with a rapidly entangling/disentangling quantum circuit followed by measurement to infer class labels of data samples.</span></span>
<span data-ttu-id="19dff-108">Het doel is om te zorgen voor klassieke karakte Rise ring en opslag van subject-circuits, evenals hybride quantum/klassieke training van de para meters van de circuits, zelfs voor extreem grote functie ruimten.</span><span class="sxs-lookup"><span data-stu-id="19dff-108">The goal is to ensure classical characterization and storage of subject circuits, as well as hybrid quantum/classical training of the circuit parameters even for extremely large feature spaces.</span></span>

## <a name="classifier-architecture"></a><span data-ttu-id="19dff-109">Classificatie architectuur</span><span class="sxs-lookup"><span data-stu-id="19dff-109">Classifier architecture</span></span>

<span data-ttu-id="19dff-110">Classificatie is een machine learning taak onder Super visie, waarbij het doel heeft om klassen labels $ \{ y_1, y_2, \ldots, y_d \} $ van bepaalde gegevens voorbeelden af te leiden.</span><span class="sxs-lookup"><span data-stu-id="19dff-110">Classification is a supervised machine learning task, where the goal is to infer class labels $\{y_1,y_2,\ldots,y_d\}$ of certain data samples.</span></span> <span data-ttu-id="19dff-111">De ' training gegevensset ' is een verzameling van voor beelden $ \mathcal{D} = \{ (x, y)} $ met bekende vooraf toegewezen labels.</span><span class="sxs-lookup"><span data-stu-id="19dff-111">The "training data set" is a collection of samples $\mathcal{D}=\{(x,y)}$ with known pre-assigned labels.</span></span> <span data-ttu-id="19dff-112">Hier $x $ een gegevens voorbeeld is en $y $ is het bekend label met de naam training label.</span><span class="sxs-lookup"><span data-stu-id="19dff-112">Here $x$ is a data sample and $y$ is its known label called "training label".</span></span>
<span data-ttu-id="19dff-113">Wat lijkt op traditionele methoden, de Quantum classificatie bestaat uit drie stappen:</span><span class="sxs-lookup"><span data-stu-id="19dff-113">Somewhat similar to traditional methods, quantum classification consists of three steps:</span></span>
- <span data-ttu-id="19dff-114">gegevens codering</span><span class="sxs-lookup"><span data-stu-id="19dff-114">data encoding</span></span>
- <span data-ttu-id="19dff-115">voor bereiding van een classificatie status</span><span class="sxs-lookup"><span data-stu-id="19dff-115">preparation of a classifier state</span></span>
- <span data-ttu-id="19dff-116">meting als gevolg van de Probabilistic aard van de meting, moeten deze drie stappen meerdere keren worden herhaald.</span><span class="sxs-lookup"><span data-stu-id="19dff-116">measurement Due to the probabilistic nature of the measurement, these three steps must be repeated multiple times.</span></span> <span data-ttu-id="19dff-117">De code ring en het berekenen van de classificatie status worden uitgevoerd door middel van *Quantum circuits*.</span><span class="sxs-lookup"><span data-stu-id="19dff-117">Both the encoding and the computing of the classifier state are done by means of *quantum circuits*.</span></span> <span data-ttu-id="19dff-118">Terwijl het coderings circuit meestal gegevensgestuurd en zonder para meters is, bevat het classificatie circuit een voldoende set leer bare para meters.</span><span class="sxs-lookup"><span data-stu-id="19dff-118">While the encoding circuit is usually data-driven and parameter-free, the classifier circuit contains a sufficient set of learnable parameters.</span></span> 

<span data-ttu-id="19dff-119">In de voorgestelde oplossing is het Classifier-circuit samengesteld uit single-Qubit rotaties en twee Qubit bestuurde rotaties.</span><span class="sxs-lookup"><span data-stu-id="19dff-119">In the proposed solution the classifier circuit is composed of single-qubit rotations and two-qubit controlled rotations.</span></span> <span data-ttu-id="19dff-120">De para meters die hier kunnen worden beschreven, zijn de draai hoek.</span><span class="sxs-lookup"><span data-stu-id="19dff-120">The learnable parameters here are the rotation angles.</span></span> <span data-ttu-id="19dff-121">De rotatie-en beheerde rotatie poorten zijn bekend als *universeel* voor Quantum berekeningen, wat betekent dat elke matrix van unitary Weight kan worden opgesplitst in een lang genoeg circuit dat uit dergelijke Gates bestaat.</span><span class="sxs-lookup"><span data-stu-id="19dff-121">The rotation and controlled rotation gates are known to be *universal* for quantum computation, which means that any unitary weight matrix can be decomposed into a long enough circuit consisting of such gates.</span></span>

<span data-ttu-id="19dff-122">In de voorgestelde versie wordt slechts één circuit gevolgd door een schatting van één frequentie ondersteund.</span><span class="sxs-lookup"><span data-stu-id="19dff-122">In the proposed version, only one circuit followed by a single frequency estimation is supported.</span></span>
<span data-ttu-id="19dff-123">De oplossing is dus een Quantum analoog van een Support Vector machine met een polynoom met een geringe graad.</span><span class="sxs-lookup"><span data-stu-id="19dff-123">Thus, the solution is a quantum analog of a support vector machine with a low-degree polynomial kernel.</span></span>

![Gecentreerde classificatie met meerdere lagen Perceptron versus circuit](~/media/DLvsQCC.png)

<span data-ttu-id="19dff-125">Een eenvoudig Quantum classificatie ontwerp kan worden vergeleken met een traditionele SVM-oplossing (Support Vector machine).</span><span class="sxs-lookup"><span data-stu-id="19dff-125">A simple quantum classifier design can be compared to a traditional support vector machine (SVM) solution.</span></span> <span data-ttu-id="19dff-126">De deinterferentie voor een gegevens voorbeeld $x $ in het geval van SVM wordt uitgevoerd met behulp van een optimale kernel-vorm $ \sum \ alpha_j k (x_j, x) $, waarbij $k $ een bepaalde kernel-functie is.</span><span class="sxs-lookup"><span data-stu-id="19dff-126">The inference for a data sample $x$ in case of SVM is done using an optimal kernel form $\sum \alpha_j  k(x_j,x)$ where $k$ is a certain kernel function.</span></span>

<span data-ttu-id="19dff-127">Een Quantum classificatie maakt daarentegen gebruik van de Voorspellings $p (y │ x, U (\theta)) = 〈 U (\theta) x | M | U (\theta) x 〉 $, die vergelijkbaar is in geest, maar technisch heel verschillend is.</span><span class="sxs-lookup"><span data-stu-id="19dff-127">By contrast, a quantum classifier uses the predictor $p(y│x,U(\theta))=〈U(\theta)x|M|U(\theta)x〉$, which is similar in spirit but technically quite different.</span></span> <span data-ttu-id="19dff-128">Als er een directe amplitude-code ring wordt gebruikt, is $p (y │ x, U (\theta)) $ een kwadratisch formulier in de amplitudes van $x $, maar worden de coëfficiënten van dit formulier niet meer afzonderlijk geleerd. ze worden in plaats daarvan geaggregeerd op basis van de matrix elementen van het circuit $U (\theta) $, dat doorgaans aanzienlijk minder meer informatie heeft dan de dimensie van de vector $x $.</span><span class="sxs-lookup"><span data-stu-id="19dff-128">Thus, when a straightforward amplitude encoding is used,  $p(y│x,U(\theta))$ is a quadratic form in the amplitudes of $x$, but the coefficients of this form are no longer learned independently; they are instead aggregated from the matrix elements of the circuit $U(\theta)$, which typically has significantly fewer learnable parameters $\theta$ than the dimension of the vector $x$.</span></span> <span data-ttu-id="19dff-129">De polynomiale mate van $p (y │ x, U (\theta)) $ in de oorspronkelijke functies kan worden verhoogd tot $2 ^ l $ door gebruik te maken van een Quantum product codering op $l $-exemplaren van $x $.</span><span class="sxs-lookup"><span data-stu-id="19dff-129">The polynomial degree of $p(y│x,U(\theta))$ in the original features can be increased to $2^l$ by using a quantum product encoding on $l$ copies of $x$.</span></span>

<span data-ttu-id="19dff-130">Onze architectuur verkent relatief recente circuits, die daarom snel moeten worden *entangling* om alle correlaties tussen de gegevens functies in alle bereiken vast te leggen.</span><span class="sxs-lookup"><span data-stu-id="19dff-130">Our architecture explores relatively shallow circuits, which therefore must be *rapidly entangling* in order to capture all the correlations between the data features at all ranges.</span></span> <span data-ttu-id="19dff-131">Hieronder ziet u een voor beeld van het handigste snelle entangling-circuit onderdeel.</span><span class="sxs-lookup"><span data-stu-id="19dff-131">An example of the most useful rapidly entangling circuit component is shown on figure below.</span></span> <span data-ttu-id="19dff-132">Hoewel een circuit met deze geometrie uit slechts $3 n + 1 $ Gates bestaat, zorgt de unitary-matrix van het gewicht dat deze reken kundige invloed heeft op een aanzienlijke Kruis communicatie tussen $2 ^ n $-functies.</span><span class="sxs-lookup"><span data-stu-id="19dff-132">Even though a circuit with this geometry consists of only $3 n+1$ gates, the unitary weight matrix that it computes ensures significant cross-talk between $2^n$ features.</span></span>

![Snel entangling Quantum circuit op 5 qubits (met twee cyclische lagen).](~/media/5-qubit-qccc.png)

<span data-ttu-id="19dff-134">Het circuit in het bovenstaande voor beeld bestaat uit 6 single-Qubit Gates (G_1, \ldots, G_5; G_ {16} ) $ en 10 2-qubits Gates $ (G_6, \ldots, G_ {15} ) $.</span><span class="sxs-lookup"><span data-stu-id="19dff-134">The circuit in the above example consists of 6 single-qubit gates $(G_1,\ldots,G_5; G_{16})$ and 10 two-qubits gates $(G_6,\ldots,G_{15})$.</span></span> <span data-ttu-id="19dff-135">Ervan uitgaande dat elk van de poorten is gedefinieerd met één para meter die kan worden leren, hebben we 16 para meters die kunnen worden leren, terwijl de dimensie van de 5-Qubit Hilbert-ruimte 32 is.</span><span class="sxs-lookup"><span data-stu-id="19dff-135">Assuming that each of the gates is defined with one learnable parameter we have 16 learnable parameters, while the dimension of the 5-qubit Hilbert space is 32.</span></span> <span data-ttu-id="19dff-136">Een dergelijk circuit geometrie kan eenvoudig worden gegeneraliseerd tot een $n $-Qubit-REGI ster, wanneer $n $ oneven is, circuits met $3 n + 1 $ para meters voor $2 ^ n $-dimensionale functie ruimte.</span><span class="sxs-lookup"><span data-stu-id="19dff-136">Such circuit geometry can be easily generalized to any $n$-qubit register, when $n$ is odd, yielding circuits with $3 n+1$ parameters for $2^n$-dimensional feature space.</span></span>

## <a name="classifier-training-as-a-supervised-learning-task"></a><span data-ttu-id="19dff-137">Geclassificeerde training als een gesuperd leer taak</span><span class="sxs-lookup"><span data-stu-id="19dff-137">Classifier training as a supervised learning task</span></span>

<span data-ttu-id="19dff-138">De training van een classificatie model omvat het vinden van optimale waarden van de operationele para meters, zodat deze de gemiddelde waarschijnlijkheid van het uitstellen van de juiste opleidings labels in de trainings voorbeelden maximaliseren.</span><span class="sxs-lookup"><span data-stu-id="19dff-138">Training of a classifier model involves finding optimal values of its operational parameters, such that they maximize the average likelihood of inferring the correct training labels across the training samples.</span></span>
<span data-ttu-id="19dff-139">Hier hebben we zelf met alleen classificatie op twee niveaus, d.w.z. het geval van $d = $2 en slechts twee klassen met de labels $y _1, y_2 $.</span><span class="sxs-lookup"><span data-stu-id="19dff-139">Here, we concern ourselves with two level classification only, i.e. the case of $d=2$ and only two classes with the labels $y_1,y_2$.</span></span>

> [!NOTE]
> <span data-ttu-id="19dff-140">Een methode om onze methoden te generaliseren voor een wille keurig aantal klassen is het vervangen van qubits met qudits, dat wil zeggen Quantum eenheden met $d $ basis Staten en de tweerichtings meting met $d $-Way meting.</span><span class="sxs-lookup"><span data-stu-id="19dff-140">A principled way of generalizing our methods to arbitrary number of classes is to replace qubits with qudits, i.e. quantum units with $d$ basis states, and the two-way measurement with $d$-way measurement.</span></span>

### <a name="likelihood-as-the-training-goal"></a><span data-ttu-id="19dff-141">Waarschijnlijkheid als het trainings doel</span><span class="sxs-lookup"><span data-stu-id="19dff-141">Likelihood as the training goal</span></span>

<span data-ttu-id="19dff-142">Gezien een lees bare Quantum circuit $U (\theta) $, waarbij $ \theta $ een vector van para meters is, en het identificeren van de uiteindelijke meting door $M $, is de gemiddelde kans op het juiste label degelijkheid $ $ \begin{align} \mathcal{L} (\theta) = \frac {1} {| \mathcal{D} |} \left (\ sum_ {(x, y_1) \In\mathcal{D}} P (M = y_1 | U (\theta) x) + \ sum_ {(x, y_2) \in\mathcal{D}} P (M = y_2 | U (\theta) x) \right) \end{align} $ $ waarbij $P (M = y | z) $ de kans is dat $y $ in de Quantum status $z $ wordt gemeten.</span><span class="sxs-lookup"><span data-stu-id="19dff-142">Given a learnable quantum circuit $U(\theta)$, where $\theta$ is a vector of parameters, and denoting the final measurement by $M$, the average likelihood of the correct label inference is $$ \begin{align} \mathcal{L}(\theta)=\frac{1}{|\mathcal{D}|} \left( \sum_{(x,y_1)\in\mathcal{D}} P(M=y_1|U(\theta) x) + \sum_{(x,y_2)\in\mathcal{D}} P(M=y_2|U(\theta) x)\right) \end{align} $$ where $P(M=y|z)$ is the probability of measuring $y$ in quantum state $z$.</span></span>
<span data-ttu-id="19dff-143">Hier is het goed om te begrijpen dat de waarschijnlijke functie $ \mathcal{L} (\theta) $ soepel is in $ \theta $ en de afgeleide in een $ \ theta_j $ kan worden berekend met behulp van het gebruikte Quantum protocol dat wordt gebruikt voor het berekenen van de waarschijnlijke functie.</span><span class="sxs-lookup"><span data-stu-id="19dff-143">Here, it suffices to understand that the likelihood function $\mathcal{L}(\theta)$ is smooth in $\theta$ and its derivative in any $\theta_j$ can be computed by essentially the same quantum protocol as used for computing the likelihood function itself.</span></span> <span data-ttu-id="19dff-144">Hierdoor kunt u de $ \mathcal{L} (\theta) $ per verloop Daal optimaliseren.</span><span class="sxs-lookup"><span data-stu-id="19dff-144">This allows for optimizing the $\mathcal{L}(\theta)$ by gradient descent.</span></span>

### <a name="classifier-bias-and-training-score"></a><span data-ttu-id="19dff-145">Classificatie afwijking en trainings Score</span><span class="sxs-lookup"><span data-stu-id="19dff-145">Classifier bias and training score</span></span>

<span data-ttu-id="19dff-146">Gezien sommige tussenliggende (of laatste) waarden van de para meters in $ \theta $, moeten we een enkele reële waarde identificeren $b $ weet als *Classifier-afwijking* om de deinterferentie uit te voeren.</span><span class="sxs-lookup"><span data-stu-id="19dff-146">Given some intermediate (or final) values of the parameters in $\theta$, we need to identify a single real value $b$ know as *classifier bias* to do the inference.</span></span> <span data-ttu-id="19dff-147">De regel voor het afwijzen van labels werkt als volgt:</span><span class="sxs-lookup"><span data-stu-id="19dff-147">The label inference rule works as follows:</span></span> 
- <span data-ttu-id="19dff-148">Een voor beeld $x $ is toegewezen label $y _2 $ if en alleen als $P (M = y_2 | U (\theta) x) + b > $0,5 (FIREWALLREGEL1) (anders is het label toegewezen $y _1 $)</span><span class="sxs-lookup"><span data-stu-id="19dff-148">A sample $x$ is assigned label $y_2$ if and only if $P(M=y_2|U(\theta) x) + b > 0.5$  (RULE1) (otherwise it is assigned label $y_1$)</span></span>

<span data-ttu-id="19dff-149">Een duidelijk $b $ moet in het interval $ (-0,5, + 0,5) $ liggen om betekenisvol te zijn.</span><span class="sxs-lookup"><span data-stu-id="19dff-149">Clearly $b$ must be in the interval $(-0.5,+0.5)$ to be meaningful.</span></span>

<span data-ttu-id="19dff-150">Een trainings case $ (x, y) \in \mathcal{D} $ wordt beschouwd als een onechte *classificatie* , gezien de bias $b $ als het label dat is uitgesteld voor $x $ zoals per firewallregel1 een andere naam heeft dan $y $.</span><span class="sxs-lookup"><span data-stu-id="19dff-150">A training case $(x,y) \in \mathcal{D}$ is considered a *misclassification* given the bias $b$ if the label inferred for $x$ as per RULE1 is actually different from $y$.</span></span> <span data-ttu-id="19dff-151">Het totale aantal misclassificaties is de *trainings Score* van de classificatie, gezien de bias $b $.</span><span class="sxs-lookup"><span data-stu-id="19dff-151">The overall number of misclassifications is the *training score* of the classifier given the bias $b$.</span></span> <span data-ttu-id="19dff-152">De *optimale* Classifier-afwijking $b $ minimaliseert de trainings Score.</span><span class="sxs-lookup"><span data-stu-id="19dff-152">The *optimal* classifier bias $b$ minimizes the training score.</span></span> <span data-ttu-id="19dff-153">Het is eenvoudig te zien dat, gezien de vooraf berekende waarschijnlijke schattingen $ \{ P (M = y_2 | U (\theta) x) | (x, \*) \in\mathcal{D} \} $, de optimale classificatie afwijking kan worden gevonden door binaire zoek opdracht in interval $ (-0,5, + 0,5) $ door Maxi maal $ \ log_2 te maken (| \mathcal{D} |) $ stappen.</span><span class="sxs-lookup"><span data-stu-id="19dff-153">It is easy to see that, given the precomputed probability estimates $\{ P(M=y_2|U(\theta) x) | (x,\*)\in\mathcal{D} \}$, the optimal classifier bias can be found by binary search in interval $(-0.5,+0.5)$ by making at most $\log_2(|\mathcal{D}|)$ steps.</span></span>

### <a name="reference"></a><span data-ttu-id="19dff-154">Naslaginformatie</span><span class="sxs-lookup"><span data-stu-id="19dff-154">Reference</span></span>

<span data-ttu-id="19dff-155">Deze informatie moet voldoende zijn om met de code te kunnen spelen.</span><span class="sxs-lookup"><span data-stu-id="19dff-155">This information should be enough to start playing with the code.</span></span> <span data-ttu-id="19dff-156">Als u echter meer wilt weten over dit model, leest u het oorspronkelijke voor stel: [ *' circuit-georiënteerde Quantum classificaties ', Maria schuld, Alex Bocharov, Krysta Svore en Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span><span class="sxs-lookup"><span data-stu-id="19dff-156">However, if you want to learn more about this model, please read the original proposal: [*'Circuit-centric quantum classifiers', Maria Schuld, Alex Bocharov, Krysta Svore and Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span></span>

<span data-ttu-id="19dff-157">Naast het code voorbeeld dat u in de volgende stappen ziet, kunt u ook beginnen met het verkennen van de Quantum classificatie in [deze zelf studie](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification) .</span><span class="sxs-lookup"><span data-stu-id="19dff-157">In addition to the code sample you will see in the next steps, you can also start exploring quantum classification in [this tutorial](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification)</span></span> 
